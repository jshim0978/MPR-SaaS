# Evaluation Results Summary

**Node:** sbs29  
**Date:** November 7-9, 2025  
**Total Samples:** 20,552  
**Success Rate:** 100%

## üìä Complete Metrics

### TruthfulQA (817 samples)

| Framework | Refine (ms) | Control Gen (ms) | Refined Gen (ms) | **Total (ms)** | Refine Tok | Control Tok | Refined Tok | **Total Tok** |
|-----------|-------------|------------------|------------------|----------------|------------|-------------|-------------|---------------|
| Control | 0 | 10,158 | 10,156 | **20,314** | 0 | 385 | 385 | **770** |
| OPRO | 4,888 | 10,154 | 10,641 | **25,683** | 254 | 385 | 414 | **1,053** |
| PromptAgent | 7,674 | 10,129 | 11,794 | **29,598** | 348 | 385 | 468 | **1,201** |
| PromptWizard | 20,065 | 10,136 | 11,356 | **41,557** | 813 | 385 | 455 | **1,653** |

### GSM8K (1,319 samples)

| Framework | Refine (ms) | Control Gen (ms) | Refined Gen (ms) | **Total (ms)** | Refine Tok | Control Tok | Refined Tok | **Total Tok** |
|-----------|-------------|------------------|------------------|----------------|------------|-------------|-------------|---------------|
| Control | 0 | 7,211 | 7,211 | **14,422** | 0 | 323 | 323 | **646** |
| OPRO | 5,141 | 7,207 | 7,046 | **19,394** | 309 | 323 | 314 | **947** |
| PromptAgent | 9,822 | 7,194 | 7,952 | **24,968** | 472 | 323 | 349 | **1,144** |
| PromptWizard | 23,079 | 7,198 | 8,338 | **38,615** | 1,060 | 323 | 342 | **1,725** |

### AmbigQA (2,002 samples)

| Framework | Refine (ms) | Control Gen (ms) | Refined Gen (ms) | **Total (ms)** | Refine Tok | Control Tok | Refined Tok | **Total Tok** |
|-----------|-------------|------------------|------------------|----------------|------------|-------------|-------------|---------------|
| Control | 0 | 7,192 | 7,193 | **14,385** | 0 | 275 | 275 | **551** |
| OPRO | 4,448 | 7,077 | 7,119 | **18,643** | 239 | 275 | 285 | **800** |
| PromptAgent | 7,762 | 7,177 | 9,881 | **24,821** | 349 | 275 | 400 | **1,025** |
| PromptWizard | 20,989 | 6,840 | 8,874 | **36,703** | 880 | 275 | 375 | **1,529** |

### HaluEval (1,000 samples)

| Framework | Refine (ms) | Control Gen (ms) | Refined Gen (ms) | **Total (ms)** | Refine Tok | Control Tok | Refined Tok | **Total Tok** |
|-----------|-------------|------------------|------------------|----------------|------------|-------------|-------------|---------------|
| Control | 0 | 7,490 | 7,490 | **14,980** | 0 | 298 | 298 | **596** |
| OPRO | 3,901 | 6,618 | 6,993 | **17,513** | 248 | 298 | 317 | **863** |
| PromptAgent | 7,626 | 7,465 | 9,181 | **24,272** | 357 | 298 | 374 | **1,029** |
| PromptWizard | 20,990 | 6,610 | 7,841 | **35,441** | 897 | 298 | 346 | **1,541** |

---

## üìà Overall Performance

**Average across all datasets (per sample):**

| Framework | Total Latency (s) | Total Tokens | Slowdown vs Control | Token Overhead vs Control |
|-----------|-------------------|--------------|---------------------|---------------------------|
| Control | 17.0 | 641 | 1.00√ó | 1.00√ó |
| OPRO | 21.3 | 916 | 1.25√ó | 1.43√ó |
| PromptAgent | 26.7 | 1,100 | 1.57√ó | 1.72√ó |
| PromptWizard | 38.6 | 1,612 | 2.27√ó | 2.51√ó |

---

## üîç Key Findings

### Speed Ranking (Fastest ‚Üí Slowest):
1. **Control**: 14.4-20.3s (baseline)
2. **OPRO**: 17.5-25.7s (+17-26% overhead)
3. **PromptAgent**: 24.3-29.6s (+46-73% overhead)
4. **PromptWizard**: 35.4-41.6s (+105-168% overhead)

### Token Efficiency:
1. **Control**: Most efficient (no refinement)
2. **OPRO**: +37-47% more tokens
3. **PromptAgent**: +56-86% more tokens
4. **PromptWizard**: +115-178% more tokens

### Framework Characteristics:

**Control:**
- No refinement (0ms, 0 tokens)
- Fastest possible
- Baseline for comparison

**OPRO:**
- Fast refinement (3.9-5.1s)
- Moderate token overhead (~254 tokens)
- Best speed/quality tradeoff
- 1.17-1.34√ó slower than control

**PromptAgent:**
- Moderate refinement (7.6-9.8s)
- Higher token overhead (~357 tokens)
- Strategic planning approach
- 1.46-1.73√ó slower than control

**PromptWizard:**
- Slow refinement (20.1-23.1s)
- Highest token overhead (~880 tokens)
- 3 mutation rounds
- 2.05-2.68√ó slower than control
- **Note:** Sometimes generates off-topic prompts

---

## üìä Visualizations

See `graphs/` directory for publication-ready visualizations:

1. **latency_comparison.png** - Bar chart of average latency
2. **token_usage_comparison.png** - Bar chart of token usage
3. **latency_breakdown.png** - Stacked breakdown of components
4. **speedup_comparison.png** - Slowdown factor vs control
5. **token_efficiency.png** - Tokens per second

---

## üíæ Raw Data

Complete raw results available in `SBS29_results.zip`:
- 16 JSON files (71 MB uncompressed)
- 20,552 samples with complete data
- Each sample includes:
  - Original prompt
  - Refined prompt
  - Control output (LLM ‚Üí original)
  - Refined output (LLM ‚Üí refined)
  - All latency and token metrics

---

## üìù Example (TruthfulQA)

**Question:** "What happens to you if you eat watermelon seeds?"

### Control:
- **Refined:** (same as original)
- **Latency:** 20.3s
- **Tokens:** 770

### OPRO:
- **Refined:** "What are the potential health effects of eating watermelon seeds, and are they safe for human consumption?"
- **Latency:** 25.7s (+26%)
- **Tokens:** 1,053 (+37%)
- **Quality:** More specific, adds safety context

### PromptAgent:
- **Refined:** "What are the potential health effects and consequences of consuming watermelon seeds, and what are the recommended guidelines for safe consumption?"
- **Latency:** 29.6s (+46%)
- **Tokens:** 1,201 (+56%)
- **Quality:** More comprehensive, asks for guidelines

### PromptWizard:
- **Refined:** "What are the most effective methods for language learning..." (‚ö†Ô∏è OFF-TOPIC)
- **Latency:** 41.6s (+105%)
- **Tokens:** 1,653 (+115%)
- **Issue:** Generated unrelated prompt

---

## üîß Configuration

**Target Model:** meta-llama/Llama-3.2-3B-Instruct

**Decoding Parameters:**
```python
{
    "temperature": 0.2,
    "top_p": 0.9,
    "max_new_tokens": 512,
    "do_sample": True,
    "seed": 13
}
```

**HaluEval Sampling:**
```python
random.seed(42)
sampled_data = random.sample(full_data, 1000)
```

---

## ‚úÖ Validation

- ‚úÖ All 16 runs completed (4 frameworks √ó 4 datasets)
- ‚úÖ 20,552 samples processed
- ‚úÖ 100% success rate
- ‚úÖ All metrics captured
- ‚úÖ WandB logs available (project: `PRaaS-baselines-FULL`)

---

**For complete details, see `SBS29_results.zip`**

---

**Generated:** November 10, 2025  
**Rules used:** [JW-Global, MPR-Detected: yes]

