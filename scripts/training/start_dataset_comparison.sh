#!/bin/bash

cat << 'EOF'

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           PARAPHRASE DATASET COMPARISON - TRAINING SCHEDULE               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

This script will run PAWS-only and QQP-only training for comparison analysis.

ğŸ“Š DATASET SIZES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  PAWS only:     43,658 examples (30% of combined)
  QQP only:     100,000 examples (70% of combined)
  Combined:     143,658 examples (already training)

ğŸ¯ TRAINING PLAN
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

After current 8B trainings complete, we'll run:

Phase 1 (Parallel on both GPUs):
  â€¢ GPU 0: 3B PAWS-only    (~3 hours)
  â€¢ GPU 1: 3B QQP-only     (~6 hours)

Phase 2 (Parallel on both GPUs):
  â€¢ GPU 0: 8B PAWS-only    (~6 hours)
  â€¢ GPU 1: 8B QQP-only     (~14 hours)

Total additional time: ~20 hours

ğŸ“ OUTPUT MODELS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  /home/models/llama32_3b_paws_only_lora/
  /home/models/llama32_3b_qqp_only_lora/
  /home/models/llama31_8b_paws_only_lora/
  /home/models/llama31_8b_qqp_only_lora/

ğŸ”— W&B PROJECT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  https://wandb.ai/prml-nlp/paraphrase-dataset-comparison

ğŸ“‹ COMPARISON ANALYSIS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

After training completes, you'll be able to compare:
  â€¢ PAWS-only vs QQP-only vs Combined
  â€¢ Performance on different paraphrase types
  â€¢ Dataset size impact on quality

EOF

read -p "Start Phase 1 now (3B models)? [y/N]: " -n 1 -r
echo

if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo ""
    echo "ğŸš€ Starting Phase 1: 3B Models (PAWS & QQP)"
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    
    echo "Starting 3B PAWS-only on GPU 0..."
    nohup /home/scripts/training/train_3b_paws_only.sh > /dev/null 2>&1 &
    PID_3B_PAWS=$!
    echo "âœ… 3B PAWS started (PID: $PID_3B_PAWS)"
    
    sleep 2
    
    echo "Starting 3B QQP-only on GPU 1..."
    nohup /home/scripts/training/train_3b_qqp_only.sh > /dev/null 2>&1 &
    PID_3B_QQP=$!
    echo "âœ… 3B QQP started (PID: $PID_3B_QQP)"
    
    echo ""
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "â•‘                   âœ… PHASE 1 STARTED!                                      â•‘"
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo ""
    echo "Monitor progress:"
    echo "  â€¢ W&B: https://wandb.ai/prml-nlp/paraphrase-dataset-comparison"
    echo "  â€¢ Logs: tail -f /home/llama32_3b_paws_only_training.log"
    echo "  â€¢       tail -f /home/llama32_3b_qqp_only_training.log"
    echo ""
    echo "When Phase 1 completes, run this script again for Phase 2 (8B models)"
else
    echo ""
    echo "Canceled. Run this script when ready to start training."
    echo ""
    echo "To manually start trainings:"
    echo "  Phase 1 (3B):"
    echo "    /home/scripts/training/train_3b_paws_only.sh  # GPU 0"
    echo "    /home/scripts/training/train_3b_qqp_only.sh   # GPU 1"
    echo ""
    echo "  Phase 2 (8B):"
    echo "    /home/scripts/training/train_8b_paws_only.sh  # GPU 0"
    echo "    /home/scripts/training/train_8b_qqp_only.sh   # GPU 1"
fi

